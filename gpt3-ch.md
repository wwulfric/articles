## 摘要

近期的研究表明，在大型文本语料库上进行预训练，然后针对特定任务进行微调，可以在许多NLP任务和基准测试中取得显著成果。尽管这种方法在架构上通常不针对特定任务，但它仍然需要由数千或数万个样本组成的任务特定微调数据集。相比之下，人类通常只需几个示例或简单的指令就能完成新的语言任务，然而当前的NLP系统在很大程度上仍难以实现这一目标。在这里，我们展示了通过扩大语言模型规模可以极大地提高任务通用的少样本性能，有时甚至能达到与先前最先进的微调方法相媲美的水平。具体来说，我们训练了GPT-3，一种具有1750亿参数的自回归语言模型，比以前任何非稀疏语言模型多10倍，并在少样本设置中测试其性能。对于所有任务，GPT-3均无需进行任何梯度更新或微调，任务和少样本演示仅通过与模型的文本交互进行指定。GPT-3在许多NLP数据集上表现优异，包括翻译、问答和填空任务，以及一些需要实时推理或领域自适应[^dat]的任务，如还原打乱的单词、在句子中使用新词或进行3位数算术运算。同时，我们还发现了，GPT-3在一些数据集上的少样本学习仍然存在困难，同时在一些大型网络语料库数据集的训练中遇到了一些方法论问题。最后，我们发现GPT-3可以生成新闻文章样本，人类评估者很难将其与人类撰写的文章区分开来。我们讨论了这一发现以及GPT-3总体产生的更广泛的社会影响。

## 1. 导言

近年来，NLP系统中出现了一个趋势，即使用越来越灵活、任务无关的方式应用预训练的「语言表示」来进行下游迁移。首先，利用词向量来学习单层表示[MCCD13, PSM14]并输入到任务特定的架构中，然后使用具有多层表示和上下文状态的RNN形成更强大的表示[DL15, MBXS17, PNZtY18]（尽管仍应用于任务特定的架构），最近则直接微调预训练的循环或Transformer语言模型[VSP+17]，完全消除了任务特定架构的需求[RNSS18, DCLT18, HR18]。 

最后这种范式在许多具有挑战性的NLP任务上取得了实质性进展，如阅读理解、问答、文本蕴涵等，并在新的架构和算法的基础上不断发展[RSR+19, LOG+19, YDY+19, LCG+19]。然而，这种方法的一个主要局限性在于，尽管架构是任务通用的，但仍然需要任务特定的数据集和任务特定的微调：要在期望的任务上取得优异表现，通常需要在针对该任务的数千到数十万个示例的数据集上进行微调。消除这种局限性是可取的，原因有以下几点。

首先，从实践角度来看，每个新任务都需要大量已标注样本的数据集限制了语言模型的应用范围。有非常多的有用的语言任务，包括纠正语法、生成抽象概念示例、评论短篇小说等等。对于这些任务中的很多来说，收集大量监督训练数据集极具挑战，尤其是当这个过程需要为每个新任务重复进行的时候。

其次，随着模型表达能力愈发强大和训练数据分布愈发狭窄，挖掘训练数据中的非实质性关联的潜力也随之增加。这给预训练加微调范式带来了问题，在这个范式中，模型被设计成庞大的，以便在预训练阶段吸收信息，但随后会在非常狭窄的任务分布上进行微调。例如，有研究发现，大模型并不一定在分布之外具有更好的泛化能力。有证据表明，在这种范式下所实现的泛化性能可能较差，因为模型过于依赖训练分布，在其之外泛化能力不足。因此，在特定基准测试上微调模型的性能，即使名义上达到人类水平，也可能高估了其在实际任务中的表现。

第三，人类在学习大部分语言任务时，并不需要大量的有监督数据集。一条简短的自然语言指令（例如，“请告诉我这句话描述的是快乐还是悲伤”）或者仅有的几个示例（例如，“这里有两个勇敢行为的例子；请给出第三个勇敢的例子”）通常就足以让人类具备至少一定程度的能力来执行新任务。除了揭示我们目前的NLP技术在概念上的局限性之外，这种适应能力还具有实际优势——它使人类能够在许多任务和技能之间无缝地混合或切换，如在漫长的对话过程中进行加法运算。为了使NLP系统更具实用性，我们期望未来的NLP系统能够拥有与人类相同的灵活性和通用性。



[^dat]: 在自然语言处理（NLP）中，领域自适应任务（domain adaptation task）主要指的是将在一个领域（源领域）训练的模型调整为适应另一个领域（目标领域）的任务。由于不同领域的数据分布可能存在差异，直接将源领域的模型应用于目标领域可能会导致性能下降。因此，领域自适应的目标是通过利用目标领域的数据，使模型更好地适应和处理目标领域的任务。领域自适应的挑战在于，在许多情况下，目标领域的标注数据是有限的或者根本不存在。为了解决这个问题，研究人员采用了多种方法，包括：特征选择或变换，无监督或半监督领域自适应，自监督学习